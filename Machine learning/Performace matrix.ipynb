{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-18T19:12:20.475659Z",
     "start_time": "2025-09-18T19:12:20.418188Z"
    }
   },
   "source": [
    "# pip install scikit-learn numpy\n",
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, roc_curve, precision_recall_curve,\n",
    "    average_precision_score, log_loss, brier_score_loss,\n",
    "    r2_score, mean_squared_error, mean_absolute_error,\n",
    "    cohen_kappa_score, matthews_corrcoef, classification_report,\n",
    "    adjusted_rand_score, normalized_mutual_info_score, silhouette_score\n",
    ")\n",
    "\n",
    "def binary_counts(y_true, y_pred, positive=1):\n",
    "    # returns TP, FP, FN, TN\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    TP = int(((y_true == positive) & (y_pred == positive)).sum())\n",
    "    FP = int(((y_true != positive) & (y_pred == positive)).sum())\n",
    "    FN = int(((y_true == positive) & (y_pred != positive)).sum())\n",
    "    TN = int(((y_true != positive) & (y_pred != positive)).sum())\n",
    "    return TP, FP, FN, TN\n",
    "\n",
    "def metrics_from_confusion(TP, FP, FN, TN):\n",
    "    N = TP+FP+FN+TN\n",
    "    acc = (TP+TN)/N if N>0 else np.nan\n",
    "    precision = TP/(TP+FP) if (TP+FP)>0 else np.nan\n",
    "    recall = TP/(TP+FN) if (TP+FN)>0 else np.nan\n",
    "    specificity = TN/(TN+FP) if (TN+FP)>0 else np.nan\n",
    "    npv = TN/(TN+FN) if (TN+FN)>0 else np.nan\n",
    "    f1 = 2*precision*recall/(precision+recall) if (precision+recall)>0 else np.nan\n",
    "    # MCC careful with zero denominators\n",
    "    denom = np.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))\n",
    "    mcc = (TP*TN - FP*FN)/denom if denom>0 else np.nan\n",
    "    return {\n",
    "        'N':N,'accuracy':acc,'precision':precision,'recall':recall,\n",
    "        'specificity':specificity,'npv':npv,'f1':f1,'mcc':mcc\n",
    "    }\n",
    "\n",
    "# Example using sklearn and manual:\n",
    "def full_binary_report(y_true, y_pred, y_score=None, positive=1):\n",
    "    TP, FP, FN, TN = binary_counts(y_true, y_pred, positive=positive)\n",
    "    cm_metrics = metrics_from_confusion(TP,FP,FN,TN)\n",
    "    report = {\n",
    "        'confusion_matrix': np.array([[TP, FN],[FP, TN]]),\n",
    "        'from_confusion': cm_metrics,\n",
    "        # sklearn\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'precision_macro': precision_score(y_true, y_pred, pos_label=positive),\n",
    "        'recall_macro': recall_score(y_true, y_pred, pos_label=positive),\n",
    "        'f1': f1_score(y_true, y_pred, pos_label=positive),\n",
    "        'cohen_kappa': cohen_kappa_score(y_true, y_pred),\n",
    "        'mcc': matthews_corrcoef(y_true, y_pred),\n",
    "        'classification_report': classification_report(y_true, y_pred, digits=4)\n",
    "    }\n",
    "    if y_score is not None:\n",
    "        y_score = np.asarray(y_score)\n",
    "        # ROC-AUC (needs both classes present)\n",
    "        try:\n",
    "            report['roc_auc'] = roc_auc_score(y_true, y_score)\n",
    "        except Exception:\n",
    "            report['roc_auc'] = np.nan\n",
    "        # PR / AP\n",
    "        try:\n",
    "            report['average_precision'] = average_precision_score(y_true, y_score)\n",
    "        except Exception:\n",
    "            report['average_precision'] = np.nan\n",
    "        # log-loss, brier\n",
    "        try:\n",
    "            report['log_loss'] = log_loss(y_true, y_score)\n",
    "        except Exception:\n",
    "            report['log_loss'] = np.nan\n",
    "        try:\n",
    "            report['brier'] = brier_score_loss(y_true, y_score)\n",
    "        except Exception:\n",
    "            report['brier'] = np.nan\n",
    "    return report\n",
    "\n",
    "# Regression helpers\n",
    "def regression_report(y_true, y_pred, adjusted=False, p=None):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    n = len(y_true)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    out = {'n':n, 'mse':mse, 'rmse':rmse, 'mae':mae, 'r2':r2}\n",
    "    if adjusted:\n",
    "        if p is None:\n",
    "            raise ValueError(\"Provide p = number of predictors for adjusted R2\")\n",
    "        out['r2_adj'] = 1 - (1-r2)*(n-1)/(n-p-1)\n",
    "    return out\n",
    "\n",
    "# Binary demo\n",
    "y_true = [1,1,0,0,1,0,1,0,0,1]\n",
    "y_pred = [1,0,0,0,1,0,1,1,0,1]\n",
    "y_score = [0.9,0.4,0.2,0.1,0.86,0.05,0.78,0.6,0.01,0.95]\n",
    "r = full_binary_report(y_true, y_pred, y_score)\n",
    "print(r['from_confusion'])\n",
    "print(r['classification_report'])\n",
    "\n",
    "# Regression demo\n",
    "y_t = [2.4, 0.5, 2.2, 1.9, 3.1]\n",
    "y_p = [2.5, 0.6, 2.0, 2.1, 3.0]\n",
    "print(regression_report(y_t, y_p, adjusted=True, p=1))\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'N': 10, 'accuracy': 0.8, 'precision': 0.8, 'recall': 0.8, 'specificity': 0.8, 'npv': 0.8, 'f1': 0.8000000000000002, 'mcc': np.float64(0.6)}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8000    0.8000    0.8000         5\n",
      "           1     0.8000    0.8000    0.8000         5\n",
      "\n",
      "    accuracy                         0.8000        10\n",
      "   macro avg     0.8000    0.8000    0.8000        10\n",
      "weighted avg     0.8000    0.8000    0.8000        10\n",
      "\n",
      "{'n': 5, 'mse': 0.022000000000000033, 'rmse': np.float64(0.14832396974191336), 'mae': 0.1400000000000001, 'r2': 0.9700109051254089, 'r2_adj': 0.9600145401672119}\n"
     ]
    }
   ],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
