{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# The Ultimate Guide to Gradient Descent\n",
    "\n",
    "Gradient Descent is the backbone of modern machine learning. It's an optimization algorithm used to find the values of parameters (coefficients) of a function that minimizes a cost function. In simple terms, it's a method to find the lowest point of a valley.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. The Core Concept: Walking Down a Hill ‚õ∞Ô∏è\n",
    "\n",
    "Imagine you are on a foggy hill and need to find its lowest point. You can only see the ground at your feet. The most straightforward strategy is to:\n",
    "1.  Look at the slope of the ground where you are.\n",
    "2.  Identify the direction that goes steepest downhill.\n",
    "3.  Take a small step in that direction.\n",
    "4.  Repeat the process until you can't go any lower.\n",
    "\n",
    "\n",
    "\n",
    "This is precisely how Gradient Descent works.\n",
    "\n",
    "* **The Hill**: This is our **cost function** ($J(\\theta)$), which measures how wrong our model's predictions are.\n",
    "* **Your Position**: This represents the current values of your model's parameters ($\\theta$).\n",
    "* **The Direction**: This is the negative of the **gradient** ($-\\nabla J(\\theta)$). The gradient is a vector that points in the direction of the steepest *increase*, so we move in the opposite direction.\n",
    "* **The Step Size**: This is the **learning rate** ($\\alpha$). It controls how big of a step we take.\n",
    "\n",
    "### The Master Formula\n",
    "\n",
    "The core of Gradient Descent is the update rule. We repeatedly update the parameters in the opposite direction of the gradient.\n",
    "\n",
    "$$\n",
    "\\theta_{\\text{new}} := \\theta_{\\text{old}} - \\alpha \\nabla J(\\theta_{\\text{old}})\n",
    "$$\n",
    "\n",
    "Where:\n",
    "* $\\theta$ is the vector of model parameters.\n",
    "* $\\alpha$ is the learning rate.\n",
    "* $\\nabla J(\\theta)$ is the gradient of the cost function $J$ with respect to the parameters $\\theta$.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Types of Gradient Descent\n",
    "\n",
    "The main difference between the types of Gradient Descent is the amount of data used to compute the gradient at each step.\n",
    "\n",
    "\n",
    "\n",
    "### A. Batch Gradient Descent (BGD)\n",
    "\n",
    "BGD calculates the gradient using the **entire training dataset** for each parameter update.\n",
    "\n",
    "* **Pros**: Smooth, stable convergence. Guaranteed to reach the global minimum for convex problems.\n",
    "* **Cons**: Very slow and computationally expensive for large datasets.\n",
    "\n",
    "### B. Stochastic Gradient Descent (SGD)\n",
    "\n",
    "SGD updates the parameters using the gradient calculated from **just one randomly chosen training sample** at each step.\n",
    "\n",
    "* **Pros**: Much faster per iteration. The noisy steps can help escape shallow local minima.\n",
    "* **Cons**: High variance in updates leads to an erratic path. It never fully converges but oscillates around the minimum.\n",
    "\n",
    "### C. Mini-Batch Gradient Descent (MBGD)\n",
    "\n",
    "MBGD is the most common approach. It computes the gradient on small, random subsets of the data called **mini-batches**.\n",
    "\n",
    "* **Pros**: A good balance between the stability of BGD and the speed of SGD. It leverages hardware optimizations for matrix operations.\n",
    "* **Cons**: Adds a new hyperparameter: the batch size.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Application 1: Linear Regression üìà\n",
    "\n",
    "Used to predict a continuous value.\n",
    "\n",
    "### Mathematical Derivation\n",
    "\n",
    "1.  **Hypothesis Function** (a straight line):\n",
    "    $$\n",
    "    h_\\theta(x) = \\theta_0 + \\theta_1 x_1 + ... + \\theta_n x_n = \\theta^T x\n",
    "    $$\n",
    "\n",
    "2.  **Cost Function** (Mean Squared Error - MSE):\n",
    "    $$\n",
    "    J(\\theta) = \\frac{1}{2m} \\sum_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)})^2\n",
    "    $$\n",
    "\n",
    "3.  **Gradient (Partial Derivatives)**: The derivative of the cost function with respect to a single parameter $\\theta_j$ is:\n",
    "    $$\n",
    "    \\frac{\\partial J(\\theta)}{\\partial \\theta_j} = \\frac{1}{m} \\sum_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)}) x_j^{(i)}\n",
    "    $$\n",
    "\n",
    "4.  **Update Rule**:\n",
    "    $$\n",
    "    \\theta_j := \\theta_j - \\alpha \\frac{1}{m} \\sum_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)}) x_j^{(i)}\n",
    "    $$\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Application 2: Logistic Regression ‚úÖ/‚ùå\n",
    "\n",
    "Used for binary classification (output is 0 or 1).\n",
    "\n",
    "### Mathematical Derivation\n",
    "\n",
    "1.  **Hypothesis Function** (using the Sigmoid function to get a probability between 0 and 1):\n",
    "    $$\n",
    "    h_\\theta(x) = g(\\theta^T x) = \\frac{1}{1 + e^{-\\theta^T x}}\n",
    "    $$\n",
    "\n",
    "2.  **Cost Function** (Log Loss or Binary Cross-Entropy):\n",
    "    $$\n",
    "    J(\\theta) = -\\frac{1}{m} \\sum_{i=1}^{m} [y^{(i)} \\log(h_\\theta(x^{(i)})) + (1 - y^{(i)}) \\log(1 - h_\\theta(x^{(i)}))]\n",
    "    $$\n",
    "\n",
    "3.  **Gradient (Partial Derivatives)**: Miraculously, the derivative of this complex function simplifies to the same form as linear regression's gradient!\n",
    "    $$\n",
    "    \\frac{\\partial J(\\theta)}{\\partial \\theta_j} = \\frac{1}{m} \\sum_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)}) x_j^{(i)}\n",
    "    $$\n",
    "    The **only difference** is that $h_\\theta(x)$ is now the sigmoid function.\n",
    "\n",
    "4.  **Update Rule** (Identical form to linear regression):\n",
    "    $$\n",
    "    \\theta_j := \\theta_j - \\alpha \\frac{1}{m} \\sum_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)}) x_j^{(i)}\n",
    "    $$"
   ],
   "id": "2ea9120265694929"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Batch Gradient Descent (BGD)\n",
    "\n",
    "**Batch Gradient Descent (BGD)** is the most straightforward implementation of the gradient descent algorithm. For every single step it takes, it calculates the gradient of the cost function using the **entire training dataset**.\n",
    "\n",
    "---\n",
    "\n",
    "### ## The Core Idea: The Full-Map Approach\n",
    "\n",
    "Imagine you are trying to find the lowest point in a valley, and you have a complete topographical map of the entire area. BGD is like looking at this entire map to calculate the single best downhill direction and then taking one confident step. You repeat this process, consulting the full map each time.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### ## Mathematical Formulation\n",
    "\n",
    "The update rule for BGD is based on the average gradient across all training examples.\n",
    "\n",
    "1.  **Cost Function Gradient** (for a specific parameter $\\theta_j$): The gradient is calculated by summing the errors over all *m* samples.\n",
    "    $$\n",
    "    \\frac{\\partial J(\\theta)}{\\partial \\theta_j} = \\frac{1}{m} \\sum_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)}) x_j^{(i)}\n",
    "    $$\n",
    "\n",
    "2.  **Parameter Update Rule**: The parameters are updated once per epoch, after the full gradient has been calculated.\n",
    "    $$\n",
    "    \\theta_j := \\theta_j - \\alpha \\frac{\\partial J(\\theta)}{\\partial \\theta_j}\n",
    "    $$\n",
    "\n",
    "---\n",
    "\n",
    "### ## Pros and Cons\n",
    "\n",
    "#### **Pros:**\n",
    "* **Stable Convergence**: The path towards the minimum is smooth and not erratic.\n",
    "* **Guaranteed Convergence**: It is guaranteed to converge to the global minimum for convex cost functions and a local minimum for non-convex ones.\n",
    "\n",
    "#### **Cons:**\n",
    "* **Very Slow**: It is incredibly slow on large datasets because it must process every single training example to perform just one update.\n",
    "* **Memory Intensive**: The entire dataset must be loaded into memory, which can be infeasible for massive datasets.\n",
    "\n",
    "---\n",
    "\n",
    "### ## When to Use It\n",
    "\n",
    "BGD is suitable for smaller datasets that can comfortably fit in memory. It's also a good learning tool because its behavior is simple to understand, but it is rarely used in modern deep learning practice due to its inefficiency."
   ],
   "id": "a5861943bd68aa64"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Stochastic Gradient Descent (SGD)\n",
    "\n",
    "**Stochastic Gradient Descent (SGD)** is a much faster variant of gradient descent. Instead of using the entire dataset, SGD updates the model's parameters using the gradient calculated from **just one randomly chosen training sample** at each step.\n",
    "\n",
    "---\n",
    "\n",
    "### ## The Core Idea: The Blindfolded Compass Approach\n",
    "\n",
    "Imagine you are again in a valley, but this time you are blindfolded and can only feel the slope of the ground right under your feet. SGD is like quickly checking this slope at one spot, taking an immediate step in the downhill direction, and then repeating this process at a new random spot. The path will be zigzagged and erratic, but you'll move down the valley very quickly.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### ## Mathematical Formulation\n",
    "\n",
    "The update rule for SGD is applied for each individual training sample.\n",
    "\n",
    "1.  **Cost Function Gradient** (for a single sample *i*): The gradient is computed for one sample at a time, so the summation and averaging terms are removed.\n",
    "    $$\n",
    "    \\frac{\\partial J(\\theta, x^{(i)}, y^{(i)})}{\\partial \\theta_j} = (h_\\theta(x^{(i)}) - y^{(i)}) x_j^{(i)}\n",
    "    $$\n",
    "\n",
    "2.  **Parameter Update Rule**: The parameters are updated for every single sample. If you have 1,000 samples, you perform 1,000 updates in one epoch.\n",
    "    $$\n",
    "    \\theta_j := \\theta_j - \\alpha \\frac{\\partial J(\\theta, x^{(i)}, y^{(i)})}{\\partial \\theta_j}\n",
    "    $$\n",
    "\n",
    "---\n",
    "\n",
    "### ## Pros and Cons\n",
    "\n",
    "#### **Pros:**\n",
    "* **Fast**: It is computationally much faster per iteration than BGD.\n",
    "* **Escapes Local Minima**: The noisy, random steps can help the algorithm jump out of shallow local minima and find a better overall minimum.\n",
    "\n",
    "#### **Cons:**\n",
    "* **High Variance**: The updates are erratic, causing the cost function to fluctuate heavily.\n",
    "* **Noisy Convergence**: It never truly \"converges\" but continues to oscillate around the global minimum. The learning rate often needs to be gradually decreased to help it settle.\n",
    "\n",
    "---\n",
    "\n",
    "### ## When to Use It\n",
    "\n",
    "SGD is useful for very large datasets where BGD would be too slow. The term \"SGD\" is often used colloquially in deep learning to refer to Mini-Batch Gradient Descent, but true one-sample SGD is valuable for online learning scenarios where data comes in as a stream."
   ],
   "id": "1c8c9cab0b6752a9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Mini-Batch Gradient Descent (MBGD)\n",
    "\n",
    "**Mini-Batch Gradient Descent (MBGD)** is the go-to method for training most machine learning and deep learning models. It combines the best of both Batch GD and Stochastic GD by calculating the gradient on a **small, random subset of the data** called a \"mini-batch\".\n",
    "\n",
    "---\n",
    "\n",
    "### ## The Core Idea: The Sectional Map Approach\n",
    "\n",
    "This is the practical compromise. You're in the valley, and instead of looking at the entire map (like BGD) or just the ground under your feet (like SGD), you look at a small, coherent section of the map (a mini-batch). This gives you a good-enough estimate of the downhill direction, allowing you to take a reasonably confident step.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### ## Mathematical Formulation\n",
    "\n",
    "The update rule is an average over the samples in the mini-batch.\n",
    "\n",
    "1.  **Cost Function Gradient** (for a mini-batch *B* of size *b*): The gradient is the average over all samples within the mini-batch.\n",
    "    $$\n",
    "    \\frac{\\partial J(\\theta, B)}{\\partial \\theta_j} = \\frac{1}{b} \\sum_{i \\in B} (h_\\theta(x^{(i)}) - y^{(i)}) x_j^{(i)}\n",
    "    $$\n",
    "\n",
    "2.  **Parameter Update Rule**: The parameters are updated after each mini-batch is processed.\n",
    "    $$\n",
    "    \\theta_j := \\theta_j - \\alpha \\frac{\\partial J(\\theta, B)}{\\partial \\theta_j}\n",
    "    $$\n",
    "\n",
    "---\n",
    "\n",
    "### ## Pros and Cons\n",
    "\n",
    "#### **Pros:**\n",
    "* **Efficient and Fast**: It strikes a balance between the speed of SGD and the stability of BGD.\n",
    "* **Hardware Optimization**: It takes full advantage of the efficiencies of matrix operations on modern hardware like GPUs.\n",
    "* **Stable Convergence**: It has a much less noisy convergence path than SGD.\n",
    "\n",
    "#### **Cons:**\n",
    "* **New Hyperparameter**: It introduces the `batch_size`, which needs to be tuned for optimal performance.\n",
    "\n",
    "---\n",
    "\n",
    "### ## When to Use It\n",
    "\n",
    "**Almost always.** Mini-Batch Gradient Descent is the standard algorithm used for training neural networks and other large-scale machine learning models. It provides a highly efficient and stable way to navigate the cost function landscape. Typical batch sizes are powers of 2, such as 32, 64, 128, or 256."
   ],
   "id": "15bc5d39b71e4661"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
