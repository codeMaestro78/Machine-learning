{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# In-Depth Guide to Key Continuous Distributions\n",
    "\n",
    "This guide provides a comprehensive overview of six fundamental continuous probability distributions: Uniform, Normal (Gaussian), Exponential, Student's t, Chi-square, and F. For each distribution, we include its definition, support, probability density function (PDF), cumulative distribution function (CDF), moments, entropy, hazard function (where relevant), estimation, relationships, sampling methods, and practical applications. All mathematical expressions are presented in LaTeX.\n",
    "\n",
    "## 1. Continuous Uniform $\\mathcal{U}(a, b)$\n",
    "\n",
    "**Definition:** The uniform distribution models equal likelihood over a finite interval $[a, b]$.\n",
    "\n",
    "**Parameters:** $a < b$, where $a$ and $b$ are the lower and upper bounds.\n",
    "\n",
    "**Support:** $x \\in [a, b]$.\n",
    "\n",
    "### PDF\n",
    "$$f(x) = \\begin{cases}\n",
    "\\frac{1}{b - a}, & a \\leq x \\leq b, \\\\\n",
    "0, & \\text{otherwise.}\n",
    "\\end{cases}$$\n",
    "\n",
    "### CDF\n",
    "$$F(x) = \\begin{cases}\n",
    "0, & x < a, \\\\\n",
    "\\frac{x - a}{b - a}, & a \\leq x \\leq b, \\\\\n",
    "1, & x > b.\n",
    "\\end{cases}$$\n",
    "\n",
    "### Quantile (Inverse CDF)\n",
    "$$Q(p) = a + (b - a)p, \\quad 0 \\leq p \\leq 1.$$\n",
    "\n",
    "### Moments and Properties\n",
    "\n",
    "- **Mean:** $\\mathbb{E}[X] = \\frac{a + b}{2}$\n",
    "- **Variance:** $\\mathrm{Var}(X) = \\frac{(b - a)^2}{12}$\n",
    "- **Mode:** Any $x \\in [a, b]$\n",
    "- **Median:** $\\frac{a + b}{2}$\n",
    "- **Entropy:** $H(X) = \\ln(b - a)$\n",
    "- **Moment Generating Function (MGF):**\n",
    "  $$M_X(t) = \\begin{cases}\n",
    "  \\frac{e^{tb} - e^{ta}}{(b - a)t}, & t \\neq 0, \\\\\n",
    "  1, & t = 0.\n",
    "  \\end{cases}$$\n",
    "- **Characteristic Function (CF):**\n",
    "  $$\\varphi_X(t) = \\frac{e^{itb} - e^{ita}}{i t (b - a)}.$$\n",
    "\n",
    "### Likelihood and MLE\n",
    "\n",
    "For a sample $x_1, \\dots, x_n$:\n",
    "$$\\mathcal{L}(a, b) = \\prod_{i=1}^n \\frac{\\mathbf{1}\\{a \\leq x_i \\leq b\\}}{b - a} = \\frac{\\mathbf{1}\\{a \\leq x_{(1)}, x_{(n)} \\leq b\\}}{(b - a)^n},$$\n",
    "where $x_{(1)} = \\min_i x_i$, $x_{(n)} = \\max_i x_i$.\n",
    "\n",
    "**Maximum Likelihood Estimators (MLEs):**\n",
    "- $\\hat{a} = x_{(1)}$\n",
    "- $\\hat{b} = x_{(n)}$\n",
    "\n",
    "**Note:** This is a non-regular estimation problem; standard Fisher information is not applicable.\n",
    "\n",
    "### Sampling\n",
    "Generate $X = a + (b - a)U$, where $U \\sim \\mathcal{U}(0, 1)$.\n",
    "\n",
    "### Hazard Function\n",
    "- **Survival:** $S(x) = 1 - \\frac{x - a}{b - a}$ for $x \\in [a, b]$.\n",
    "- **Hazard:** $h(x) = \\frac{1}{b - x}$, increasing to infinity at $x = b$.\n",
    "\n",
    "### When to Use\n",
    "- Modeling complete ignorance within a bounded interval.\n",
    "- Random offsets or simulation baselines.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Normal (Gaussian) $\\mathcal{N}(\\mu, \\sigma^2)$\n",
    "\n",
    "**Definition:** The normal distribution models additive effects and is central to statistics due to the Central Limit Theorem (CLT).\n",
    "\n",
    "**Parameters:** $\\mu \\in \\mathbb{R}$ (mean), $\\sigma > 0$ (standard deviation).\n",
    "\n",
    "**Support:** $x \\in \\mathbb{R}$.\n",
    "\n",
    "### PDF\n",
    "$$f(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp\\left( -\\frac{(x - \\mu)^2}{2\\sigma^2} \\right).$$\n",
    "\n",
    "### CDF\n",
    "No elementary form; denoted as:\n",
    "$$F(x) = \\Phi\\left( \\frac{x - \\mu}{\\sigma} \\right),$$\n",
    "where $\\Phi$ is the CDF of the standard normal $\\mathcal{N}(0, 1)$.\n",
    "\n",
    "### Standardization\n",
    "If $X \\sim \\mathcal{N}(\\mu, \\sigma^2)$, then:\n",
    "$$Z = \\frac{X - \\mu}{\\sigma} \\sim \\mathcal{N}(0, 1).$$\n",
    "\n",
    "### Moments and Properties\n",
    "\n",
    "- **Mean:** $\\mathbb{E}[X] = \\mu$\n",
    "- **Variance:** $\\mathrm{Var}(X) = \\sigma^2$\n",
    "- **Skewness:** 0\n",
    "- **Excess Kurtosis:** 0\n",
    "- **MGF:**\n",
    "  $$M_X(t) = \\exp\\left( \\mu t + \\frac{1}{2}\\sigma^2 t^2 \\right).$$\n",
    "- **CF:**\n",
    "  $$\\varphi_X(t) = \\exp\\left( i \\mu t - \\frac{1}{2}\\sigma^2 t^2 \\right).$$\n",
    "- **Entropy:**\n",
    "  $$H(X) = \\frac{1}{2} \\ln\\left( 2\\pi e \\sigma^2 \\right).$$\n",
    "\n",
    "### Key Identities\n",
    "\n",
    "- **Sum of independent normals:** If $X_i \\sim \\mathcal{N}(\\mu_i, \\sigma_i^2)$, then $\\sum X_i \\sim \\mathcal{N}\\left( \\sum \\mu_i, \\sum \\sigma_i^2 \\right)$.\n",
    "- **Linear transformation:** If $X \\sim \\mathcal{N}(\\mu, \\sigma^2)$, then $aX + b \\sim \\mathcal{N}(a\\mu + b, a^2 \\sigma^2)$.\n",
    "- **Central Limit Theorem (CLT):** Sums or averages of many i.i.d. variables approximate a normal distribution.\n",
    "\n",
    "### Likelihood and MLE\n",
    "\n",
    "For a sample $x_1, \\dots, x_n$:\n",
    "$$\\ell(\\mu, \\sigma^2) = -\\frac{n}{2} \\ln(2\\pi \\sigma^2) - \\frac{1}{2\\sigma^2} \\sum_{i=1}^n (x_i - \\mu)^2.$$\n",
    "\n",
    "**MLEs:**\n",
    "- $\\hat{\\mu} = \\bar{x}$\n",
    "- $\\widehat{\\sigma^2}_{\\text{MLE}} = \\frac{1}{n} \\sum_{i=1}^n (x_i - \\bar{x})^2$\n",
    "\n",
    "**Note:** Unbiased variance estimator uses $\\frac{1}{n-1}$ instead of $\\frac{1}{n}$.\n",
    "\n",
    "### Bayesian Conjugacy\n",
    "\n",
    "- **Known $\\sigma^2$:** Normal prior for $\\mu$ yields a normal posterior.\n",
    "- **Unknown $(\\mu, \\sigma^2)$:** Normal-Inverse-Gamma or Normal-Inverse-$\\chi^2$ prior.\n",
    "\n",
    "### Sampling\n",
    "Use the Box-Muller transform:\n",
    "\n",
    "1. Draw $U_1, U_2 \\stackrel{\\text{iid}}{\\sim} \\mathcal{U}(0, 1)$.\n",
    "2. Compute:\n",
    "   $$Z_1 = \\sqrt{-2 \\ln U_1} \\cos(2\\pi U_2), \\quad Z_2 = \\sqrt{-2 \\ln U_1} \\sin(2\\pi U_2).$$\n",
    "3. Set $X = \\mu + \\sigma Z_1$.\n",
    "\n",
    "### When to Use\n",
    "\n",
    "- Modeling aggregated noise or measurement errors.\n",
    "- Phenomena driven by additive effects.\n",
    "- Parametric tests relying on CLT (e.g., t-tests, ANOVA).\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Exponential $\\mathrm{Exp}(\\lambda)$\n",
    "\n",
    "**Definition:** The exponential distribution models waiting times in processes with constant hazard (memoryless property).\n",
    "\n",
    "**Parameter:** $\\lambda > 0$ (rate).\n",
    "\n",
    "**Support:** $x \\geq 0$.\n",
    "\n",
    "### PDF, CDF, Survival, and Hazard\n",
    "\n",
    "- **PDF:**\n",
    "  $$f(x) = \\lambda e^{-\\lambda x}, \\quad x \\geq 0.$$\n",
    "- **CDF:**\n",
    "  $$F(x) = 1 - e^{-\\lambda x}.$$\n",
    "- **Survival:**\n",
    "  $$S(x) = e^{-\\lambda x}.$$\n",
    "- **Hazard:**\n",
    "  $$h(x) = \\frac{f(x)}{S(x)} = \\lambda \\quad (\\text{constant}).$$\n",
    "\n",
    "### Quantile and Memorylessness\n",
    "\n",
    "- **Quantile:**\n",
    "  $$Q(p) = -\\frac{1}{\\lambda} \\ln(1 - p), \\quad 0 \\leq p < 1.$$\n",
    "- **Memoryless Property:**\n",
    "  $$\\mathbb{P}(X > s + t \\mid X > s) = \\mathbb{P}(X > t).$$\n",
    "\n",
    "### Moments and Properties\n",
    "\n",
    "- **Mean:** $\\mathbb{E}[X] = \\frac{1}{\\lambda}$\n",
    "- **Variance:** $\\mathrm{Var}(X) = \\frac{1}{\\lambda^2}$\n",
    "- **MGF:**\n",
    "  $$M_X(t) = \\frac{\\lambda}{\\lambda - t}, \\quad t < \\lambda.$$\n",
    "- **Entropy:**\n",
    "  $$H(X) = 1 - \\ln \\lambda.$$\n",
    "\n",
    "### Likelihood and MLE\n",
    "\n",
    "For a sample $x_1, \\dots, x_n$:\n",
    "$$\\ell(\\lambda) = n \\ln \\lambda - \\lambda \\sum_{i=1}^n x_i.$$\n",
    "\n",
    "**MLE:**\n",
    "$$\\hat{\\lambda} = \\frac{n}{\\sum x_i} = \\frac{1}{\\bar{x}}.$$\n",
    "\n",
    "- **Sufficient Statistic:** $\\sum x_i$.\n",
    "- **Fisher Information:** $I(\\lambda) = \\frac{n}{\\lambda^2}$.\n",
    "\n",
    "### Bayesian Conjugacy\n",
    "If $\\lambda \\sim \\mathrm{Gamma}(\\alpha, \\beta)$, the posterior is:\n",
    "$$\\lambda \\mid x_1, \\dots, x_n \\sim \\mathrm{Gamma}\\left( \\alpha + n, \\beta + \\sum x_i \\right).$$\n",
    "\n",
    "### Sampling\n",
    "Generate $X = -\\frac{\\ln U}{\\lambda}$, where $U \\sim \\mathcal{U}(0, 1)$.\n",
    "\n",
    "### When to Use\n",
    "\n",
    "- Modeling inter-arrival times in Poisson processes.\n",
    "- Systems with constant hazard (no aging).\n",
    "- Queueing theory and reliability analysis.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Student's t $\\mathrm{t}_\\nu(\\mu, s)$\n",
    "\n",
    "**Definition:** The t-distribution is used for small-sample inference and robust modeling, with heavier tails than the normal.\n",
    "\n",
    "**Parameters:** $\\mu \\in \\mathbb{R}$ (location), $s > 0$ (scale), $\\nu > 0$ (degrees of freedom). Standard form: $\\mu = 0$, $s = 1$.\n",
    "\n",
    "**Support:** $x \\in \\mathbb{R}$.\n",
    "\n",
    "### PDF\n",
    "$$f(x) = \\frac{\\Gamma\\left( \\frac{\\nu + 1}{2} \\right)}{s \\sqrt{\\nu \\pi} \\, \\Gamma\\left( \\frac{\\nu}{2} \\right)} \\left( 1 + \\frac{1}{\\nu} \\left( \\frac{x - \\mu}{s} \\right)^2 \\right)^{-\\frac{\\nu + 1}{2}}.$$\n",
    "\n",
    "### CDF (Standard Form, $\\mu = 0, s = 1$)\n",
    "Expressed using the regularized incomplete Beta function $I_z(a, b)$:\n",
    "$$F(t) = \\frac{1}{2} + \\operatorname{sgn}(t) \\cdot \\frac{1}{2} I_{\\frac{\\nu}{t^2 + \\nu}}\\left( \\frac{\\nu}{2}, \\frac{1}{2} \\right),$$\n",
    "or via hypergeometric function:\n",
    "$$F(t) = \\frac{1}{2} + t \\cdot \\frac{\\Gamma\\left( \\frac{\\nu + 1}{2} \\right)}{\\sqrt{\\nu \\pi} \\, \\Gamma\\left( \\frac{\\nu}{2} \\right)} \\, {}_2F_1\\left( \\frac{1}{2}, \\frac{\\nu + 1}{2}; \\frac{3}{2}; -\\frac{t^2}{\\nu} \\right).$$\n",
    "\n",
    "### Key Relationship\n",
    "If $Z \\sim \\mathcal{N}(0, 1)$, $V \\sim \\chi^2_\\nu$, and $Z \\perp V$, then:\n",
    "$$T = \\frac{Z}{\\sqrt{V / \\nu}} \\sim \\mathrm{t}_\\nu.$$\n",
    "For location-scale: $X = \\mu + s T$.\n",
    "\n",
    "### Moments (Standard Form)\n",
    "\n",
    "- **Mean:** $\\mathbb{E}[T] = 0$ ($\\nu > 1$)\n",
    "- **Variance:** $\\mathrm{Var}(T) = \\frac{\\nu}{\\nu - 2}$ ($\\nu > 2$)\n",
    "- **Skewness:** 0 ($\\nu > 3$)\n",
    "- **Excess Kurtosis:** $\\frac{6}{\\nu - 4}$ ($\\nu > 4$)\n",
    "- **MGF:** Does not exist.\n",
    "- **CF:** Exists but lacks a simple elementary form.\n",
    "\n",
    "### Heavy Tails and Robustness\n",
    "The t-distribution has heavier tails than the normal, making it robust to outliers, especially for small $\\nu$.\n",
    "\n",
    "### Likelihood and Estimation\n",
    "No closed-form MLEs for $(\\mu, s, \\nu)$. Numerical optimization or Expectation-Maximization (EM) is required. For fixed $\\nu$, $\\mu$ and $s$ can be estimated via iteratively reweighted least squares (IRLS).\n",
    "\n",
    "### Sampling\n",
    "\n",
    "1. Draw $Z \\sim \\mathcal{N}(0, 1)$, $V \\sim \\chi^2_\\nu$.\n",
    "2. Compute $T = \\frac{Z}{\\sqrt{V / \\nu}}$.\n",
    "3. Set $X = \\mu + s T$.\n",
    "\n",
    "### When to Use\n",
    "\n",
    "- Small-sample inference with unknown variance.\n",
    "- Robust regression modeling under outliers.\n",
    "- Bayesian models using scale mixtures of normals.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Chi-square $\\chi^2_k$\n",
    "\n",
    "**Definition:** The chi-square distribution models the sum of squared standard normals.\n",
    "\n",
    "**Parameter:** $k > 0$ (degrees of freedom).\n",
    "\n",
    "**Support:** $x > 0$.\n",
    "\n",
    "**Relationship:** If $Z_i \\stackrel{\\text{iid}}{\\sim} \\mathcal{N}(0, 1)$, then $\\sum_{i=1}^k Z_i^2 \\sim \\chi^2_k$. Equivalent to $\\mathrm{Gamma}\\left( \\frac{k}{2}, 2 \\right)$.\n",
    "\n",
    "### PDF and CDF\n",
    "\n",
    "- **PDF:**\n",
    "  $$f(x) = \\frac{1}{2^{k/2} \\Gamma(k/2)} x^{k/2 - 1} e^{-x/2}, \\quad x > 0.$$\n",
    "- **CDF:**\n",
    "  $$F(x) = \\frac{\\gamma\\left( \\frac{k}{2}, \\frac{x}{2} \\right)}{\\Gamma(k/2)},$$\n",
    "  where $\\gamma(a, x)$ is the lower incomplete gamma function.\n",
    "\n",
    "### Moments and Properties\n",
    "\n",
    "- **Mean:** $\\mathbb{E}[X] = k$\n",
    "- **Variance:** $\\mathrm{Var}(X) = 2k$\n",
    "- **Skewness:** $\\sqrt{\\frac{8}{k}}$\n",
    "- **Excess Kurtosis:** $\\frac{12}{k}$\n",
    "- **MGF:**\n",
    "  $$M_X(t) = (1 - 2t)^{-k/2}, \\quad t < \\frac{1}{2}.$$\n",
    "- **Entropy:**\n",
    "  $$H(X) = \\frac{k}{2} + \\ln\\left( 2 \\Gamma(k/2) \\right) + \\left( 1 - \\frac{k}{2} \\right) \\psi\\left( \\frac{k}{2} \\right),$$\n",
    "  where $\\psi$ is the digamma function.\n",
    "\n",
    "### Relationships\n",
    "\n",
    "- **Additivity:** If $X_1 \\sim \\chi^2_{k_1}$, $X_2 \\sim \\chi^2_{k_2}$, and $X_1 \\perp X_2$, then $X_1 + X_2 \\sim \\chi^2_{k_1 + k_2}$.\n",
    "- **F-distribution:** If $X \\sim \\chi^2_k$, $Y \\sim \\chi^2_m$, and $X \\perp Y$, then $\\frac{X/k}{Y/m} \\sim F_{k, m}$.\n",
    "\n",
    "### Estimation Use\n",
    "Used for variance tests in normal data:\n",
    "$$\\frac{(n - 1)S^2}{\\sigma^2} \\sim \\chi^2_{n - 1},$$\n",
    "where $S^2$ is the sample variance.\n",
    "\n",
    "### Sampling\n",
    "\n",
    "- Sum the squares of $k$ i.i.d. $\\mathcal{N}(0, 1)$ variates.\n",
    "- Alternatively, use a Gamma sampler with shape $\\frac{k}{2}$, scale 2.\n",
    "\n",
    "### When to Use\n",
    "\n",
    "- Variance inference for normal data.\n",
    "- Goodness-of-fit tests.\n",
    "- Components of sums of squares in ANOVA.\n",
    "- Large-sample approximations in contingency tables.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. F Distribution $F_{d_1, d_2}$\n",
    "\n",
    "**Definition:** The F-distribution models the ratio of scaled chi-square variables.\n",
    "\n",
    "**Parameters:** $d_1, d_2 > 0$ (degrees of freedom).\n",
    "\n",
    "**Support:** $x > 0$.\n",
    "\n",
    "**Relationship:** If $U \\sim \\chi^2_{d_1}$, $V \\sim \\chi^2_{d_2}$, and $U \\perp V$, then:\n",
    "$$F = \\frac{(U / d_1)}{(V / d_2)} \\sim F_{d_1, d_2}.$$\n",
    "\n",
    "### PDF and CDF\n",
    "\n",
    "- **PDF:**\n",
    "  $$f(x) = \\frac{1}{\\mathrm{B}\\left( \\frac{d_1}{2}, \\frac{d_2}{2} \\right)} \\left( \\frac{d_1}{d_2} \\right)^{d_1/2} \\frac{x^{d_1/2 - 1}}{\\left( 1 + \\frac{d_1}{d_2} x \\right)^{(d_1 + d_2)/2}}, \\quad x > 0.$$\n",
    "- **CDF:**\n",
    "  $$F(x) = I_{\\frac{d_1 x}{d_1 x + d_2}}\\left( \\frac{d_1}{2}, \\frac{d_2}{2} \\right),$$\n",
    "  where $I_z(a, b)$ is the regularized incomplete Beta function.\n",
    "\n",
    "### Moments and Properties\n",
    "\n",
    "- **Mean:** $\\mathbb{E}[F] = \\frac{d_2}{d_2 - 2}$, $d_2 > 2$\n",
    "- **Variance:**\n",
    "  $$\\mathrm{Var}(F) = \\frac{2 d_2^2 (d_1 + d_2 - 2)}{d_1 (d_2 - 2)^2 (d_2 - 4)}, \\quad d_2 > 4.$$\n",
    "- **Mode:**\n",
    "  $$\\frac{(d_1 - 2)}{d_1} \\cdot \\frac{d_2}{d_2 + 2}, \\quad d_1 > 2.$$\n",
    "\n",
    "### Relationships\n",
    "\n",
    "- If $T \\sim \\mathrm{t}_\\nu$, then $T^2 \\sim F_{1, \\nu}$.\n",
    "- **Reciprocal:** If $X \\sim F_{d_1, d_2}$, then $\\frac{1}{X} \\sim F_{d_2, d_1}$.\n",
    "\n",
    "### ANOVA and Regression\n",
    "Used in global F-tests:\n",
    "$$F = \\frac{\\text{MS}_{\\text{model}}}{\\text{MS}_{\\text{error}}} = \\frac{(SSR / d_1)}{(SSE / d_2)},$$\n",
    "where $SSR$ is the sum of squares for the model, and $SSE$ is the residual sum of squares.\n",
    "\n",
    "### Sampling\n",
    "\n",
    "1. Draw $U \\sim \\chi^2_{d_1}$, $V \\sim \\chi^2_{d_2}$.\n",
    "2. Compute $F = \\frac{U / d_1}{V / d_2}$.\n",
    "\n",
    "### When to Use\n",
    "\n",
    "- Comparing two variances.\n",
    "- Omnibus tests in ANOVA.\n",
    "- Nested model comparisons via ratio of mean squares.\n",
    "\n",
    "---\n",
    "\n",
    "## Cross-Distribution Relationships\n",
    "\n",
    "- **Uniform:** Basis for simulation; relates to other distributions via transformations (e.g., inverse CDF sampling).\n",
    "- **Normal:** Foundational due to CLT; sums of normals remain normal; standardized normal leads to $\\chi^2$, t, and F.\n",
    "- **Exponential:** Linked to Poisson processes; special case of Gamma; memoryless property is unique.\n",
    "- **t:** Arises as a ratio involving $\\mathcal{N}(0, 1)$ and $\\chi^2$; converges to normal as $\\nu \\to \\infty$.\n",
    "- **$\\chi^2$:** Sum of squared standard normals; equivalent to $\\mathrm{Gamma}(k/2, 2)$; used in t and F.\n",
    "- **F:** Ratio of scaled $\\chi^2$ variables; used in variance comparisons and ANOVA.\n",
    "\n",
    "---\n",
    "\n",
    "## When to Choose What?\n",
    "\n",
    "- **Uniform:** Use for complete ignorance within a bounded interval or simulation inputs.\n",
    "- **Normal:** Use for additive effects, measurement errors, or CLT-driven models.\n",
    "- **Exponential:** Use for waiting times with constant hazard (e.g., Poisson processes).\n",
    "- **t:** Use for small samples with unknown variance or robust modeling under outliers.\n",
    "- **$\\chi^2$:** Use for variance inference, goodness-of-fit, or sums of squares in ANOVA.\n",
    "- **F:** Use for comparing variances or omnibus tests in ANOVA and regression.\n",
    "\n",
    "---\n",
    "\n",
    "## Estimation Cheat-Sheet (i.i.d. Sample)\n",
    "\n",
    "- **Uniform $[a, b]$:** $\\hat{a} = x_{(1)}$, $\\hat{b} = x_{(n)}$ (non-regular case).\n",
    "- **Normal:** $\\hat{\\mu} = \\bar{x}$, $\\widehat{\\sigma^2}_{\\text{MLE}} = \\frac{1}{n} \\sum (x_i - \\bar{x})^2$.\n",
    "- **Exponential:** $\\hat{\\lambda} = \\frac{1}{\\bar{x}}$.\n",
    "- **t (location-scale):** No closed-form MLEs; use numerical methods.\n",
    "- **$\\chi^2_k$, $F_{d_1, d_2}$:** Degrees of freedom typically known; if unknown, use method-of-moments or numerical likelihood.\n",
    "\n",
    "---\n",
    "\n",
    "## Hazard and Survival (Reliability Perspective)\n",
    "\n",
    "- **Uniform:** Survival $S(x) = 1 - \\frac{x - a}{b - a}$, hazard $h(x) = \\frac{1}{b - x}$ (increases to infinity).\n",
    "- **Exponential:** Constant hazard $h(x) = \\lambda$, survival $S(x) = e^{-\\lambda x}$.\n",
    "- **Normal, t, $\\chi^2$, F:** No simple closed-form hazards; shapes depend on parameters (t, $\\chi^2$, and F have heavy right tails).\n",
    "\n",
    "---\n",
    "\n",
    "## Sampling Recipes\n",
    "\n",
    "- **Uniform:** $X = a + (b - a)U$, $U \\sim \\mathcal{U}(0, 1)$.\n",
    "- **Normal:** Box-Muller transform (see Normal section).\n",
    "- **Exponential:** $X = -\\frac{\\ln U}{\\lambda}$, $U \\sim \\mathcal{U}(0, 1)$.\n",
    "- **t:** Draw $Z \\sim \\mathcal{N}(0, 1)$, $V \\sim \\chi^2_\\nu$, compute $T = \\frac{Z}{\\sqrt{V / \\nu}}$, then $X = \\mu + s T$.\n",
    "- **$\\chi^2_k$:** Sum of squares of $k$ i.i.d. $\\mathcal{N}(0, 1)$ or use Gamma sampler.\n",
    "- **F:** Draw $U \\sim \\chi^2_{d_1}$, $V \\sim \\chi^2_{d_2}$, compute $F = \\frac{U / d_1}{V / d_2}$.\n",
    "\n",
    "---\n",
    "\n",
    "## Common Pitfalls\n",
    "\n",
    "- **Normal with Heavy Tails:** Use t-distribution for heavy-tailed data or small samples.\n",
    "- **Exponential Misuse:** Verify constant hazard before using for lifetimes.\n",
    "- **Variance Estimation:** MLE for normal variance uses $\\frac{1}{n}$; unbiased estimator uses $\\frac{1}{n-1}$.\n",
    "- **Uniform Endpoints:** Non-regular estimation; standard asymptotics do not apply."
   ],
   "id": "f58b3ca18b3e50d6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": "#above is the indepth knowledge of the continuous probability distributions"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
