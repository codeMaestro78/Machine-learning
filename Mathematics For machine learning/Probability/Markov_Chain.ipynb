{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b229bb3d",
   "metadata": {},
   "source": [
    "## Markov Chain(MC):\n",
    "\n",
    "A Markov chain is the mathematical model for stochastic processes where the future state dependes solely on the present state and not on the sequence of events that preceded it. this property is known as the markov property . MC used in various fields such as genetics, economics, game theory, and computer science.\n",
    "\n",
    "### Key Concepts:\n",
    "1. **States** : The different possible conditions or positions in which the system can exist.\n",
    "2. **Transition Probability** : The probability of moving from one state to another.\n",
    "3. **Transition Matrix** : A matrix that represents the transition probabilities between states.\n",
    "4. **Initial State Distribution** : The probabilities of starting in each state.\n",
    "### Example:\n",
    "Consider a simple weather model with two states: \"Sunny\"\n",
    "and \"Rainy\". The transition probabilities are as follows:\n",
    "- If today is Sunny, there is a 0.8 probability that tomorrow will be Sunny and a 0.2 probability that it will be Rainy.\n",
    "- If today is Rainy, there is a 0.4 probability that tomorrow will be Sunny and a 0.6 probability that it will be Rainy.\n",
    "The transition matrix for this Markov chain can be represented as:\n",
    "```\n",
    "        | Sunny | Rainy |\n",
    "-------------------------\n",
    "Sunny  |  0.8  |  0.2  |    \n",
    "Rainy  |  0.4  |  0.6  |\n",
    "```\n",
    "The initial state distribution could be:\n",
    "```\n",
    "        | Sunny | Rainy |\n",
    "-------------------------\n",
    "        |  0.5  |  0.5  |\n",
    "```\n",
    "This indicates that there is a 50% chance of starting in either state.\n",
    "### Applications:\n",
    "- **Weather Forecasting** : Predicting future weather conditions based on current data.\n",
    "- **Stock Market Analysis** : Modeling stock price movements.\n",
    "- **Natural Language Processing** : Text generation and speech recognition.\n",
    "- **Game Theory** : Analyzing strategies in games with probabilistic outcomes.\n",
    "Markov chains provide a powerful framework for modeling systems that evolve over time with inherent randomness.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790dde99",
   "metadata": {},
   "source": [
    "## Mathematical representation:\n",
    "Imagine a system with a finite set of states, say $   S = \\{s_1, s_2, \\dots, s_n\\}   $. At each time step $   t   $, the system is in one state $   X_t \\in S   $.\n",
    "\n",
    "Transition probabilities: The probability of moving from state $   i   $ to state $   j   $ is $   P_{ij} = P(X_{t+1} = s_j \\mid X_t = s_i)   $. These are fixed and don't change with time (assuming a time-homogeneous chain).\n",
    "\n",
    "All $   P_{ij} \\geq 0   $ and for each $   i   $, $   \\sum_j P_{ij} = 1   $ (rows sum to 1).\n",
    "\n",
    "We represent this as a transition matrix $   P   $, an $   n \\times n   $ matrix where entry (i,j) is $   P_{ij}   $.\n",
    "\n",
    "Initial state distribution: The initial probabilities of being in each state can be represented as a vector $   \\pi^{(0)} = [\\pi_1^{(0)}, \\pi_2^{(0)}, \\dots, \\pi_n^{(0)}]   $, where $   \\pi_i^{(0)} = P(X_0 = s_i)   $.\n",
    "\n",
    "The state distribution at time $   t   $ can be computed as:\n",
    "$$   \\pi^{(t)} = \\pi^{(0)} P^t   $$\n",
    "where $   P^t   $ is the matrix $   P   $ raised to the power of $   t   $.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "553dc93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "def simulate_markov_chain(transition_matrix,intial_state,num_steps):\n",
    "    curr_state=intial_state\n",
    "    state_history=[curr_state]\n",
    "\n",
    "    for _ in range(num_steps):\n",
    "        probs=transition_matrix[curr_state]\n",
    "        next_state=random.choices(range(len(probs)),weights=probs)[0]\n",
    "        curr_state=next_state\n",
    "        state_history.append(curr_state)\n",
    "    return state_history\n",
    "\n",
    "\n",
    "transition_matrix=[[0.9,0.1],[0.5,0.5]]\n",
    "\n",
    "initial_state=0\n",
    "num_steps=10\n",
    "\n",
    "print(simulate_markov_chain(transition_matrix,initial_state,num_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9334a2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.843, 0.157]\n"
     ]
    }
   ],
   "source": [
    "def estimate_steady_state(transition_matrix,initial_state,num_steps,num_trials=1000):\n",
    "    state_counts=[0]*len(transition_matrix)\n",
    "    for _ in range(num_trials):\n",
    "        states=simulate_markov_chain(transition_matrix,initial_state,num_steps)\n",
    "        state_counts[states[-1]]+=1\n",
    "    steady_state=[count/num_trials for count in state_counts]\n",
    "    return steady_state\n",
    "\n",
    "print(estimate_steady_state(transition_matrix,initial_state,num_steps))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d0839a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
